# Deaf-Blind-Communicator
## ğŸ¯ Aim
To **bridge the communication gap between blind and deaf/mute individuals** by enabling real-time, two-way interaction using **speech-to-text** and **text-to-speech** technologies.

---

## ğŸ’¡ Project Overview
This desktop-based Python application provides a GUI where:

- A **blind user** can speak â†’ their words are converted to text using speech recognition.
- A **deaf/mute user** can type â†’ their message is read aloud using a text-to-speech engine.
- A **webcam** detects a face before speech is recorded, ensuring speech input is intentional.
- A shared conversation box logs the entire communication, making it easy to follow.

---

## ğŸ” Features
| Feature                             | Description                                                                 |
|-------------------------------------|-----------------------------------------------------------------------------|
| ğŸ™ï¸ Speech Recognition               | Blind users speak via mic â†’ converted to text via Google Speech API        |
| âŒ¨ï¸ Text Input + TTS                 | Deaf/mute users type â†’ system speaks it using `pyttsx3`                    |
| ğŸ§  Face Detection Trigger           | Face detection (OpenCV) starts listening only when a user is visible       |
| ğŸªŸ Interactive Tkinter GUI         | Smooth and simple interface for both users                                 |
| ğŸ§¾ Conversation History             | Full two-way message log within the app                                    |
| ğŸ”„ Reset Button                     | Clears conversation for a fresh start                                      |

---

## ğŸ› ï¸ Technologies Used

- **Python 3**
- **Tkinter** â€“ GUI
- **SpeechRecognition** â€“ Speech-to-text
- **pyttsx3** â€“ Offline text-to-speech
- **OpenCV (cv2)** â€“ Face detection with webcam
- **PIL (Pillow)** â€“ To display static image (banner)

---
## ğŸ“¸ Screenshot
<img width="411" height="474" alt="image" src="https://github.com/user-attachments/assets/2e519d36-af54-4245-868f-9eb66dc11f13" />
<img width="348" height="486" alt="image" src="https://github.com/user-attachments/assets/d176eacc-6fec-49f6-b0cd-d60f67a8f5bc" />
---
## â–¶ï¸ How to Run

### Step 1:Install dependencies:
pip install pyttsx3,SpeechRecognition, opencv-python, pillow

Step 2: Run the app
python Kalpana_Hackathon_final.py
---

## ğŸš€ Future Enhancements
- ğŸ§  **Language translation**: Support multilingual communication (e.g., Hindi â†” English).
- ğŸ“¡ **Offline speech recognition**: For use in low-internet areas using models like Vosk.
- ğŸ“² **Mobile/Tablet version**: Develop an Android app using Kivy or Flutter.
- ğŸ§¾ **Save/export conversation**: Allow saving the chat log to a file (e.g., PDF or TXT).
- ğŸ¨ **Accessibility mode**: Increase text size, contrast, or voice speed for better usability.
- ğŸ”Š **Voice gender/accents**: Allow TTS customization for regional inclusivity.

## ğŸŒ Impact
This system can significantly improve day-to-day interactions for differently-abled individuals, especially in educational institutions, healthcare centers, or public services. It's a step toward inclusive communication using accessible and affordable technology.

## ğŸ‘©â€ğŸ’» Author
**Divya Gupta**  
Passionate about building AI tools that solve real-world problems.


